{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804ca8df-44e2-40fd-b581-17b65f0c73b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/falcon2212/college/sem8/PE/detr-tensorflow/environments', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '', '/home/falcon2212/college/sem8/PE/detr-tensorflow/environments/facemaskdetector_env/lib/python3.7/site-packages', '/home/falcon2212/college/sem8/PE/detr-tensorflow/environments/facemaskdetector_env/lib/python3.7/site-packages/IPython/extensions', '/home/falcon2212/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Set the path to the repository here\n",
    "print(sys.path)\n",
    "sys.path.append(\"/home/falcon2212/college/sem8/PE/detr-tensorflow/\")\n",
    "import detr_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc13062a-ad10-4398-9505-47b66acda3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 1:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb083a3-e4d3-4339-9638-aa87f3f3f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.training_config import TrainingConfig\n",
    "from os.path import expanduser\n",
    "import os\n",
    "\n",
    "class CustomConfig(TrainingConfig):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # Dataset info\n",
    "        self.datadir = os.path.join(expanduser(\"/home/falcon2212/college/sem8/PE\"), \"data/hardhat/\")\n",
    "        # The model is trained using fixed size images.\n",
    "        # The following is the desired target image size, but it can be change based on your\n",
    "        # dataset\n",
    "        self.image_size = (480, 720)\n",
    "        # Batch size\n",
    "        self.batch_size = 1\n",
    "        # Using the target batch size , the training loop will agregate the gradient on 38 steps\n",
    "        # before to update the weights\n",
    "        self.target_batch = 8\n",
    "\n",
    "config = CustomConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6285014f-ed12-488a-be01-6d1ad8e90afb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d499c7a684e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetr_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tfcsv_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset and exclude the person class (for some reason not all person are labeled on the training set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tfcsv_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"person\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tfcsv_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"person\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/college/sem8/PE/detr-tensorflow/detr_tf/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_coco_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOCO_CLASS_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_voc_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtfcsv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tfcsv_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#import processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#import transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/college/sem8/PE/detr-tensorflow/detr_tf/data/tfcsv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from detr_tf.data import load_tfcsv_dataset\n",
    "\n",
    "# Load the dataset and exclude the person class (for some reason not all person are labeled on the training set)\n",
    "train_iterator, class_names = load_tfcsv_dataset(\"train\", config.batch_size, config, augmentation=True, exclude=[\"person\"])\n",
    "valid_iterator, class_names = load_tfcsv_dataset(\"test\", config.batch_size, config, augmentation=False, exclude=[\"person\"])\n",
    "print(\"class_names\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a380347-19c3-475f-b957-18dbb2769b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.networks.detr import get_detr_model\n",
    "# Load the pretrained DETR model with new heads at the top\n",
    "# include_top: We do not include the last layers that predicts the bbox pos and class (include_top=False)\n",
    "# nb_class: We add new layers on top of the model to predicts the bbox pos and class with three class (nb_class=3), background, helmet, face\n",
    "# weights: Use the \"detr\" weight to init the model\n",
    "detr = get_detr_model(config, include_top=False, nb_class=3, weights=\"detr\")\n",
    "detr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9bb5e-872e-4f1c-902e-0864645e1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/finetune the transformers only\n",
    "config.train_backbone = tf.Variable(False)\n",
    "config.train_transformers = tf.Variable(False)\n",
    "config.train_nlayers = tf.Variable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a253d7a-3254-416b-8c56-fa9ca3533833",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.nlayers_lr = tf.Variable(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba41c10-ae1e-46bd-9be3-2df7e95d04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.optimizers import setup_optimizers\n",
    "# Setup the optimziers and the trainable variables\n",
    "optimzers = setup_optimizers(detr, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee3b69-c796-4125-b49b-825171f3243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf import training\n",
    "training.fit(detr, train_iterator, optimzers, config, epoch_nb=0, class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
